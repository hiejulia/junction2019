{"remainingRequest":"/Users/hien/Desktop/vue-argon-dashboard-master/node_modules/vue-loader/lib/index.js??vue-loader-options!/Users/hien/Desktop/vue-argon-dashboard-master/src/views/CameraView.vue?vue&type=script&lang=js&","dependencies":[{"path":"/Users/hien/Desktop/vue-argon-dashboard-master/src/views/CameraView.vue","mtime":1573974223415},{"path":"/Users/hien/Desktop/vue-argon-dashboard-master/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/Users/hien/Desktop/vue-argon-dashboard-master/node_modules/babel-loader/lib/index.js","mtime":499162500000},{"path":"/Users/hien/Desktop/vue-argon-dashboard-master/node_modules/cache-loader/dist/cjs.js","mtime":499162500000},{"path":"/Users/hien/Desktop/vue-argon-dashboard-master/node_modules/vue-loader/lib/index.js","mtime":499162500000}],"contextDependencies":[],"result":["//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n//\n\nimport Camera from \"vue-html5-camera\"\nimport axios from 'axios';\nimport fs from 'fs'\n\nconst vision = require('@google-cloud/vision')\n\n// Imports the Google Cloud client library\nconst {Storage} = require('@google-cloud/storage');\n// Creates a client\nconst storage = new Storage();\nconst bucket = storage.bucket(\"junctionimages\")\nconst base64 = require('node-base64-image'); \nconst credentials = require('../auth/creds.json');\n\nexport default {\n  data() {\n    return {\n      src: \"\",\n      filesToUpload:[],\n      images:[],\n      uploadedImagesUrl:[],\n      progress:0,\n      uploaded:false,\n      uploadStart:false\n    }\n  },\n  methods: {\n  dataURIToBlob(dataURI) {\n    dataURI = dataURI.replace(/^data:/, '');\n\n    const type = dataURI.match(/image\\/[^;]+/);\n    const base64 = dataURI.replace(/^[^,]+,/, '');\n    const arrayBuffer = new ArrayBuffer(base64.length);\n    const typedArray = new Uint8Array(arrayBuffer);\n\n    for (let i = 0; i < base64.length; i++) {\n        typedArray[i] = base64.charCodeAt(i);\n    }\n\n    return new Blob([arrayBuffer], {type});\n},\n    \n    blobToFile(theBlob, fileName){\n    //A Blob() is almost a File() - it's just missing the two properties below which we will add\n    theBlob.lastModifiedDate = new Date();\n    theBlob.name = fileName;\n    return theBlob;\n},\n    getPhoto() {\n      this.src = this.$refs.camera.click();\n\n\n      // Base 64 image \n\n      this.callAnnotateImage(this.src)\n\n      // End Base 64 image\n      \n//       fs.writeFile('image.png', this.src, {encoding: 'base64'}, function(err) {\n//     console.log('File created');\n// });\n    \n      // Blob type\n\n      var blobImage = this.dataURIToBlob((this.src),'emotion1')\n\n      const imageUrl = URL.createObjectURL(blobImage);\n\n      console.log(imageUrl)\n      const srcImage = URL.revokeObjectURL(imageUrl)\n    \n      var filename = this.blobToFile(blobImage)\n      \n      // Download image to the local file\n      // var a = document.createElement(\"a\"); //Create <a>\n      // a.href = this.src\n      // a.download = \"faceemotion.png\"; //File name Here\n      // a.click(); //Downloaded file\n      // End download image\n      \n\n      // Push the download file -> cloud -> get URL\n\n      // Save url to the DB\n\n      //\n\n      // return url \n      \n    },\n\n  // Extract the Emotion via photo \n\n    async callAnnotateImage(base64String) {\n\n      const client = new vision.ImageAnnotatorClient();\n\n    // const request = {\n    //     \"image\": {\n    //         \"content\": base64String\n    //     },\n    //     \"features\": [\n    //         {\n    //             \"type\": \"FACE_DETECTION\"\n    //         },\n    //         {\n    //             \"type\": \"LABEL_DETECTION\"\n    //         },\n    //         {\n    //             \"type\": \"IMAGE_PROPERTIES\"\n    //         },\n    //         {\n    //             \"type\": \"WEB_DETECTION\"\n    //         }\n    //     ],\n    // };\n\n    // try {\n    //     const call = await client.annotateImage(request);\n    //     console.log(call);\n    // } catch (error) {\n    //     console.error(error);\n    // }\n    const [result] = await client.faceDetection(base64String);\n  const faces = result.faceAnnotations;\n  console.log('Faces:');\n  faces.forEach((face, i) => {\n    console.log(`  Face #${i + 1}:`);\n    console.log(`    Joy: ${face.joyLikelihood}`);\n    console.log(`    Anger: ${face.angerLikelihood}`);\n    console.log(`    Sorrow: ${face.sorrowLikelihood}`);\n    console.log(`    Surprise: ${face.surpriseLikelihood}`);\n  });\n\n},\n\n  // End extract the Emotion via Photo \n\n    // Main function for upload\n    async uploadFile() {\n      var bucketName = \"junctionimages\"\n      var filename = this.blobToFile(this.dataURIToBlob(this.src),'emotion1')\n    // Uploads a local file to the bucket\n    await storage.bucket(bucketName).upload(filename, {\n\n    // Support for HTTP requests made with `Accept-Encoding: gzip`\n    gzip: true,\n    // By setting the option `destination`, you can change the name of the\n    // object you are uploading to a bucket.\n    metadata: {\n      // Enable long-lived HTTP caching headers\n      // Use only if the contents of the file will never change\n      // (If the contents will change, use cacheControl: 'no-cache')\n      cacheControl: 'public, max-age=31536000',\n    },\n  });\n},\n\n\nasync extractEmotions() {\n  // Imports the Google Cloud client library\n  const vision = require('@google-cloud/vision');\n  // Creates a client\n  const client = new vision.ImageAnnotatorClient();\n\n  // Performs label detection on the image file\n  const imageUrl = \"https://images.unsplash.com/photo-1467307983825-619715426c70?ixlib=rb-1.2.1&auto=format&fit=crop&w=1340&q=80\"\n  \n  const [result] = await client.labelDetection(imageUrl);\n\n  \n  const labels = result.labelAnnotations;\n  \n  labels.forEach(label => console.log(label.description));\n}\n\n    // POST - /api/upload images / users \n  },\n  components: {\n    Camera\n  }\n}\n",{"version":3,"sources":["CameraView.vue"],"names":[],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AA6CA;AACA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;;AAEA;AACA;AACA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;;AAEA;;AAEA;;AAEA;AACA;AACA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;;AAGA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA;;AAEA;;AAEA;AACA;AACA;AACA;AACA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;;;AAGA;AACA;AACA;AACA;AACA;;AAEA;AACA;;AAEA;;;AAGA;;AAEA;AACA;;AAEA;AACA;AACA;AACA;AACA;AACA","file":"CameraView.vue","sourceRoot":"src/views","sourcesContent":["<template>\n    <div>\n        <base-header class=\"header pb-8 pt-5 pt-lg-8 d-flex align-items-center\"\n                     >\n            <!-- Mask -->\n            \n        </base-header>\n\n        <div class=\"container-fluid mt--7\">\n                <!--Message part-->\n                <div class=\"col-xl-8 order-xl-1\">\n                    <card shadow type=\"secondary\">\n                        <div slot=\"header\" class=\"bg-white border-0\">\n                            <div class=\"row align-items-center\">\n                                <div class=\"col-8\">\n                                    <h3 class=\"mb-0\">Opening your camera...</h3>\n                                </div>\n                                <div class=\"col-4 text-right\">\n                                    <a href=\"#!\" class=\"btn btn-sm btn-primary\">Settings</a>\n                                </div>\n                              <!---Start the camera-->\n\n          <main>\n    <Camera ref=\"camera\" width=\"300\" height=\"300\" />\n    <button @click=\"getPhoto\">What is my emotion?</button>\n    <img alt=\"Your image\" :src=\"src\" v-if=\"src\">\n\n    <p>HAPPY - 90%</p>\n    <p>Recommendation : You are enjoy life at the bese. Good mental health is a prerequisite for good physical health. </p>\n  </main>\n\n                              <!--End the camera--->             \n                            </div>\n                        </div>\n                        \n                    </card>\n                </div>\n                <!--End Message part-->\n\n            </div>\n        </div>\n    </div>\n</template>\n\n<script>\nimport Camera from \"vue-html5-camera\"\nimport axios from 'axios';\nimport fs from 'fs'\n\nconst vision = require('@google-cloud/vision')\n\n// Imports the Google Cloud client library\nconst {Storage} = require('@google-cloud/storage');\n// Creates a client\nconst storage = new Storage();\nconst bucket = storage.bucket(\"junctionimages\")\nconst base64 = require('node-base64-image'); \nconst credentials = require('../auth/creds.json');\n\nexport default {\n  data() {\n    return {\n      src: \"\",\n      filesToUpload:[],\n      images:[],\n      uploadedImagesUrl:[],\n      progress:0,\n      uploaded:false,\n      uploadStart:false\n    }\n  },\n  methods: {\n  dataURIToBlob(dataURI) {\n    dataURI = dataURI.replace(/^data:/, '');\n\n    const type = dataURI.match(/image\\/[^;]+/);\n    const base64 = dataURI.replace(/^[^,]+,/, '');\n    const arrayBuffer = new ArrayBuffer(base64.length);\n    const typedArray = new Uint8Array(arrayBuffer);\n\n    for (let i = 0; i < base64.length; i++) {\n        typedArray[i] = base64.charCodeAt(i);\n    }\n\n    return new Blob([arrayBuffer], {type});\n},\n    \n    blobToFile(theBlob, fileName){\n    //A Blob() is almost a File() - it's just missing the two properties below which we will add\n    theBlob.lastModifiedDate = new Date();\n    theBlob.name = fileName;\n    return theBlob;\n},\n    getPhoto() {\n      this.src = this.$refs.camera.click();\n\n\n      // Base 64 image \n\n      this.callAnnotateImage(this.src)\n\n      // End Base 64 image\n      \n//       fs.writeFile('image.png', this.src, {encoding: 'base64'}, function(err) {\n//     console.log('File created');\n// });\n    \n      // Blob type\n\n      var blobImage = this.dataURIToBlob((this.src),'emotion1')\n\n      const imageUrl = URL.createObjectURL(blobImage);\n\n      console.log(imageUrl)\n      const srcImage = URL.revokeObjectURL(imageUrl)\n    \n      var filename = this.blobToFile(blobImage)\n      \n      // Download image to the local file\n      // var a = document.createElement(\"a\"); //Create <a>\n      // a.href = this.src\n      // a.download = \"faceemotion.png\"; //File name Here\n      // a.click(); //Downloaded file\n      // End download image\n      \n\n      // Push the download file -> cloud -> get URL\n\n      // Save url to the DB\n\n      //\n\n      // return url \n      \n    },\n\n  // Extract the Emotion via photo \n\n    async callAnnotateImage(base64String) {\n\n      const client = new vision.ImageAnnotatorClient();\n\n    // const request = {\n    //     \"image\": {\n    //         \"content\": base64String\n    //     },\n    //     \"features\": [\n    //         {\n    //             \"type\": \"FACE_DETECTION\"\n    //         },\n    //         {\n    //             \"type\": \"LABEL_DETECTION\"\n    //         },\n    //         {\n    //             \"type\": \"IMAGE_PROPERTIES\"\n    //         },\n    //         {\n    //             \"type\": \"WEB_DETECTION\"\n    //         }\n    //     ],\n    // };\n\n    // try {\n    //     const call = await client.annotateImage(request);\n    //     console.log(call);\n    // } catch (error) {\n    //     console.error(error);\n    // }\n    const [result] = await client.faceDetection(base64String);\n  const faces = result.faceAnnotations;\n  console.log('Faces:');\n  faces.forEach((face, i) => {\n    console.log(`  Face #${i + 1}:`);\n    console.log(`    Joy: ${face.joyLikelihood}`);\n    console.log(`    Anger: ${face.angerLikelihood}`);\n    console.log(`    Sorrow: ${face.sorrowLikelihood}`);\n    console.log(`    Surprise: ${face.surpriseLikelihood}`);\n  });\n\n},\n\n  // End extract the Emotion via Photo \n\n    // Main function for upload\n    async uploadFile() {\n      var bucketName = \"junctionimages\"\n      var filename = this.blobToFile(this.dataURIToBlob(this.src),'emotion1')\n    // Uploads a local file to the bucket\n    await storage.bucket(bucketName).upload(filename, {\n\n    // Support for HTTP requests made with `Accept-Encoding: gzip`\n    gzip: true,\n    // By setting the option `destination`, you can change the name of the\n    // object you are uploading to a bucket.\n    metadata: {\n      // Enable long-lived HTTP caching headers\n      // Use only if the contents of the file will never change\n      // (If the contents will change, use cacheControl: 'no-cache')\n      cacheControl: 'public, max-age=31536000',\n    },\n  });\n},\n\n\nasync extractEmotions() {\n  // Imports the Google Cloud client library\n  const vision = require('@google-cloud/vision');\n  // Creates a client\n  const client = new vision.ImageAnnotatorClient();\n\n  // Performs label detection on the image file\n  const imageUrl = \"https://images.unsplash.com/photo-1467307983825-619715426c70?ixlib=rb-1.2.1&auto=format&fit=crop&w=1340&q=80\"\n  \n  const [result] = await client.labelDetection(imageUrl);\n\n  \n  const labels = result.labelAnnotations;\n  \n  labels.forEach(label => console.log(label.description));\n}\n\n    // POST - /api/upload images / users \n  },\n  components: {\n    Camera\n  }\n}\n</script>\n\n\n<style></style>\n\n"]}]}